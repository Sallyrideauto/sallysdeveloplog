{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efb65f26",
   "metadata": {},
   "source": [
    "# Exploration 4. 작사가 인공지능 만들기\n",
    "\n",
    "본 과제는 파이썬의 시퀀스 자료형과 순환신경망(RNN)을 이용하여 인공지능이 문장을 읽어들이는 방식을 이해하고, 이 인공지능이 작문을 하도록 돕는다.\n",
    "\n",
    "## 과제 평가 기준\n",
    "1. 가사 텍스트 생성 모델이 정상적으로 동작하는가?<br>\n",
    "   텍스트 제너레이션 결과가 그럴듯한 문장으로 생성되는가?<br>\n",
    "2. 데이터의 전처리와 데이터셋 구성 과정이 체계적으로 진행되었는가?<br>\n",
    "   특수문자 제거, 토크나이저 생성, 패딩처리 등의 과정이 빠짐없이 진행되었는가?<br>\n",
    "3. 텍스트 생성모델이 안정적으로 학습되었는가?<br>\n",
    "   텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?<br>\n",
    "   \n",
    "* * *\n",
    "\n",
    "## 순환신경망(RNN; Recurrent Neural Network)에 대하여\n",
    "* 시계열 데이터와 같이 시간의 흐름에 따라 변화하는 데이터를 학습하기 위한 인공신경망으로, 과거의 출력 데이터를 재귀(자기 자신을 참조한다는 의미로, 현재와 이전의 결과가 연관성을 가짐을 의미)적으로 참조\n",
    "* 주로 앞뒤 데이터 간의 연관성이 있는 데이터셋에 사용되는 모델로, 음성 인식 및 번역 시스템에 많이 사용되고 있음\n",
    "* 참고 링크 : [인공지능의 이해 (5/6): 순환 신경망(RNN)](https://brunch.co.kr/@linecard/324)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63f3a9",
   "metadata": {},
   "source": [
    "## 데이터를 읽어온 후 정제하기\n",
    "glob 를 활용하여 모든 txt 파일을 읽어온 후, raw_corpus 리스트에 문장 단위로 저장한다. 그 다음 저장된 문장들을 preprocess_sentence() 함수를 활용하여 데이터를 정제한다. 문장을 토큰화 했을 시 토큰의 개수가 15개를 넘는 문장을 학습에서 제외한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09a81e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\", 'It goes like this', 'The fourth, the fifth', 'The minor fall, the major lift', 'The baffled king composing Hallelujah Hallelujah', 'Hallelujah', 'Hallelujah']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os, re \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담는다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:9]) # 앞에서부터 10라인만 화면에 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb261ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now I've heard there was a secret chord\n",
      "That David played, and it pleased the Lord\n",
      "But you don't really care for music, do you?\n",
      "It goes like this\n",
      "The fourth, the fifth\n",
      "The minor fall, the major lift\n",
      "The baffled king composing Hallelujah Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah Your faith was strong but you needed proof\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   # 길이가 0인 문장 건너뛰기\n",
    "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장 건너뛰기\n",
    "\n",
    "    if idx > 9: break   # 먼저 문장 10개만 확인하도록 하자.\n",
    "        \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afdd5828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "# 입력된 문장을\n",
    "#     1. 소문자로 바꾸고, 양쪽 공백 삭제\n",
    "#     2. 특수문자 양쪽에 공백 삽입\n",
    "#     3. 여러개의 공백은 하나의 공백으로 변환\n",
    "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 변환\n",
    "#     5. 다시 양쪽 공백을 삭제\n",
    "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    return sentence\n",
    "\n",
    "# 문장 필터링 결과 확인\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98fe5882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> now i ve heard there was a secret chord <end>',\n",
       " '<start> that david played , and it pleased the lord <end>',\n",
       " '<start> but you don t really care for music , do you ? <end>',\n",
       " '<start> it goes like this <end>',\n",
       " '<start> the fourth , the fifth <end>',\n",
       " '<start> the minor fall , the major lift <end>',\n",
       " '<start> the baffled king composing hallelujah hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah your faith was strong but you needed proof <end>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정제된 문장 수집\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    # 원하지 않는 문장 건너뛰기\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    # 정제된 문장 담기\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "# 10개의 정제된 결과 확인\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e70b9",
   "metadata": {},
   "source": [
    "## 훈련/평가 데이터셋 분리\n",
    "tokenize() 함수로 데이터를 Tensor로 변환한 후, sklearn 모듈의 train_test_split() 함수를 사용해 훈련 데이터와 평가 데이터를 분리한다. 단어장의 크기는 12,000 단어 이상이며, 총 데이터의 20%를 평가 데이터셋으로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b378784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    5 ...    0    0    0]\n",
      " [   2   17 2639 ...    0    0    0]\n",
      " [   2   36    7 ...   43    3    0]\n",
      " ...\n",
      " [   5   22    9 ...   10 1013    3]\n",
      " [  37   15 9049 ...  877  647    3]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f3ce5ce62b0>\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용\n",
    "def tokenize(corpus):\n",
    "    # 12000단어를 기억할 수 있는 tokenizer 생성\n",
    "    # 12000단어에 포함되지 못한 단어는 '<unk>'로 변환\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words = 12000, \n",
    "        filters = ' ',\n",
    "        oov_token = \"<unk>\"\n",
    "    )\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춤\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줌\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding = 'post', maxlen = 15)\n",
    "    # 토큰의 개수가 15개를 초과하는 문장 제외\n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "795a369a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    5   91  297   65   57    9  969 6042]\n",
      " [   2   17 2639  873    4    8   11 6043    6  329]\n",
      " [   2   36    7   37   15  164  282   28  299    4]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[:3, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e8a0063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a153fcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   50    5   91  297   65   57    9  969 6042    3    0    0    0]\n",
      "[  50    5   91  297   65   57    9  969 6042    3    0    0    0    0]\n",
      "Source Train :  (140599, 14)\n",
      "Target Train :  (140599, 14)\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성\n",
    "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높음\n",
    "src_input = tensor[:, :-1]  \n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])\n",
    "\n",
    "# 평가 데이터셋 분리\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
    "                                                          tgt_input,\n",
    "                                                          test_size = 0.2, \n",
    "                                                          shuffle = True, \n",
    "                                                          random_state = 32)\n",
    "\n",
    "print(\"Source Train : \", enc_train.shape)\n",
    "print(\"Target Train : \", dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59b6a4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "# tokenizer가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 0:<pad>를 포함하여 12001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "# 준비한 데이터 소스로부터 데이터셋을 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder = True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c92e85",
   "metadata": {},
   "source": [
    "## 인공지능 모델 학습시키기\n",
    "tf.keras.Model을 Subclassing하는 방식으로 모델을 만든 후, 모델의 Embedding Size와 Hidden Size를 조절해 10 Epoch 안에 val_loss 값을 2.2 수준으로 줄일 수 있는 모델을 설계한다. \n",
    "<img src=\"https://d3s0tskafalll9.cloudfront.net/media/images/E-12-4.max-800x600.png\"><br>\n",
    "\n",
    "## LSTM(Long Short-Term Memory, LSTM)\n",
    "* 전통적인 RNN(이를 바닐라 RNN이라고 한다)의 경우, 비교적 짧은 시퀀스(Sequence)에 대해서만 효과를 보이는 문제점이 존재\n",
    "* 기존 RNN의 시점(time step)이 길어질수록 앞의 정보가 뒤로 충분히 전달되지 못한다는 문제가 있음\n",
    "* LSTM은 기존 RNN이 가진 이러한 장기 의존성 문제(the problem of Long-Term Dependencies)를 보완\n",
    "* 은닉층의 메모리 셀에 입력, 망각, 출력 게이트를 추가하여 불필요한 기억을 지우고, 기억해야 할 것들을 결정함\n",
    "* 참고 링크 : [2) 장단기 메모리(Long Short-Term Memory, LSTM)](https://wikidocs.net/22888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78fb7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 512\n",
    "hidden_size = 1024\n",
    "lyricist = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "052bc766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[-6.63743485e-05,  3.62666266e-04, -9.97726511e-06, ...,\n",
       "         -1.35906244e-04, -1.20688135e-04, -2.34706022e-04],\n",
       "        [-2.55395571e-04,  7.42503325e-04,  1.43708079e-04, ...,\n",
       "         -4.24297265e-04, -3.50188056e-04, -1.67167746e-04],\n",
       "        [-5.02977986e-04,  9.70414199e-04,  3.81613558e-04, ...,\n",
       "         -5.39670582e-04, -3.15920683e-04, -5.85545349e-05],\n",
       "        ...,\n",
       "        [ 1.12316309e-04, -3.75681790e-04, -1.11192814e-03, ...,\n",
       "         -5.65824623e-04,  6.93646085e-04,  1.68304436e-03],\n",
       "        [-1.42699661e-04, -7.29323016e-04, -9.44326282e-04, ...,\n",
       "         -6.32083102e-04,  1.08422968e-03,  1.67148735e-03],\n",
       "        [-3.72330978e-04, -1.04658341e-03, -7.34705245e-04, ...,\n",
       "         -7.67060381e-04,  1.53901847e-03,  1.68981694e-03]],\n",
       "\n",
       "       [[-6.63743485e-05,  3.62666266e-04, -9.97726511e-06, ...,\n",
       "         -1.35906244e-04, -1.20688135e-04, -2.34706022e-04],\n",
       "        [-2.40007852e-04,  6.01882988e-04, -2.49757955e-04, ...,\n",
       "         -4.66298006e-05, -2.45880045e-04, -3.78544239e-04],\n",
       "        [-6.13178301e-04,  5.35300758e-04, -3.38865531e-04, ...,\n",
       "         -1.25542196e-04,  3.88886074e-05, -2.71877128e-04],\n",
       "        ...,\n",
       "        [-1.19941169e-03, -1.05218694e-03,  2.63172144e-04, ...,\n",
       "         -1.89743238e-03,  4.01448738e-03,  1.87092647e-03],\n",
       "        [-1.06332416e-03, -1.12690881e-03,  3.78559867e-04, ...,\n",
       "         -2.02207151e-03,  4.15851315e-03,  1.99227361e-03],\n",
       "        [-9.27036395e-04, -1.19588070e-03,  4.87012876e-04, ...,\n",
       "         -2.12735427e-03,  4.25218837e-03,  2.09392374e-03]],\n",
       "\n",
       "       [[ 8.94797995e-05, -2.24613919e-04,  2.73025624e-04, ...,\n",
       "         -2.53924460e-04,  6.50726579e-05,  1.53084809e-04],\n",
       "        [ 8.68369170e-05, -1.63185716e-04,  5.03115240e-04, ...,\n",
       "         -1.95694709e-04,  5.45596504e-06,  5.20871254e-04],\n",
       "        [ 1.35618742e-04,  6.86431158e-05,  4.60512529e-04, ...,\n",
       "         -5.04340394e-04, -1.26959974e-04,  8.20998102e-04],\n",
       "        ...,\n",
       "        [ 5.62266214e-04,  2.95310485e-04,  6.52028772e-04, ...,\n",
       "         -2.42602255e-04,  9.14035700e-05,  1.03281729e-03],\n",
       "        [ 2.93949590e-04,  1.79981198e-05,  9.68836830e-04, ...,\n",
       "          6.18788399e-05, -7.44870194e-05,  1.11860526e-03],\n",
       "        [-1.31667330e-04, -2.57025327e-04,  1.12307176e-03, ...,\n",
       "          2.98976782e-04, -2.20485075e-04,  8.98651837e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-6.63743485e-05,  3.62666266e-04, -9.97726511e-06, ...,\n",
       "         -1.35906244e-04, -1.20688135e-04, -2.34706022e-04],\n",
       "        [-3.80466081e-04,  6.15116383e-04, -2.39153262e-04, ...,\n",
       "         -1.80487477e-04, -4.51923523e-04, -3.28274041e-06],\n",
       "        [-3.39039660e-04,  5.94359415e-04, -4.67354199e-04, ...,\n",
       "         -4.45880250e-05, -3.38197686e-04, -2.96939106e-04],\n",
       "        ...,\n",
       "        [-1.02414269e-04,  1.03075639e-03, -5.03482122e-04, ...,\n",
       "         -2.58230517e-04, -1.27367186e-03, -7.53877175e-05],\n",
       "        [-4.20939585e-04,  5.98110782e-04, -5.67364099e-04, ...,\n",
       "         -5.29626035e-04, -7.77278154e-04,  1.13468370e-04],\n",
       "        [-7.09513668e-04,  1.65558988e-04, -5.76907303e-04, ...,\n",
       "         -8.04639712e-04, -1.30380358e-04,  3.67509201e-04]],\n",
       "\n",
       "       [[-6.63743485e-05,  3.62666266e-04, -9.97726511e-06, ...,\n",
       "         -1.35906244e-04, -1.20688135e-04, -2.34706022e-04],\n",
       "        [-5.10608515e-07,  7.00915232e-04,  5.31741643e-05, ...,\n",
       "         -3.25040222e-04, -7.02852849e-05, -6.26078865e-04],\n",
       "        [ 1.07816508e-04,  6.10951742e-04, -3.25975889e-05, ...,\n",
       "         -9.06521396e-04, -5.59355016e-04, -8.06487689e-04],\n",
       "        ...,\n",
       "        [-1.23163522e-03, -8.60810629e-04,  2.16618282e-05, ...,\n",
       "         -2.14534346e-03,  3.47542530e-03,  1.89638336e-03],\n",
       "        [-1.14359253e-03, -9.54969088e-04,  1.58793220e-04, ...,\n",
       "         -2.22136104e-03,  3.78406653e-03,  2.06116727e-03],\n",
       "        [-1.03861687e-03, -1.03776134e-03,  2.92291195e-04, ...,\n",
       "         -2.28573149e-03,  4.01488738e-03,  2.19203392e-03]],\n",
       "\n",
       "       [[-6.63743485e-05,  3.62666266e-04, -9.97726511e-06, ...,\n",
       "         -1.35906244e-04, -1.20688135e-04, -2.34706022e-04],\n",
       "        [-2.42618160e-04,  3.85534891e-04, -1.95024186e-04, ...,\n",
       "         -4.67751903e-04,  1.62901837e-04, -4.34839021e-04],\n",
       "        [-2.82521098e-04,  6.62048231e-04, -3.86810047e-04, ...,\n",
       "         -8.64995818e-04,  4.11489775e-04, -3.25045752e-04],\n",
       "        ...,\n",
       "        [-1.15517539e-03, -4.32399043e-04, -3.77637007e-05, ...,\n",
       "         -1.96834840e-03,  2.03090510e-03,  5.56055049e-04],\n",
       "        [-1.22712145e-03, -5.87749644e-04,  5.00015522e-05, ...,\n",
       "         -2.08941521e-03,  2.52775988e-03,  8.45404633e-04],\n",
       "        [-1.23809255e-03, -7.06588093e-04,  1.39348966e-04, ...,\n",
       "         -2.19437201e-03,  2.96411337e-03,  1.11071754e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러오는 방법\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 삽입\n",
    "lyricist(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f102876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "686/686 [==============================] - 123s 173ms/step - loss: 3.5766\n",
      "Epoch 2/10\n",
      "686/686 [==============================] - 126s 183ms/step - loss: 3.0824\n",
      "Epoch 3/10\n",
      "686/686 [==============================] - 126s 183ms/step - loss: 2.8738\n",
      "Epoch 4/10\n",
      "686/686 [==============================] - 126s 183ms/step - loss: 2.7073\n",
      "Epoch 5/10\n",
      "686/686 [==============================] - 126s 184ms/step - loss: 2.5618\n",
      "Epoch 6/10\n",
      "686/686 [==============================] - 126s 184ms/step - loss: 2.4298\n",
      "Epoch 7/10\n",
      "686/686 [==============================] - 127s 184ms/step - loss: 2.3052\n",
      "Epoch 8/10\n",
      "686/686 [==============================] - 127s 185ms/step - loss: 2.1875\n",
      "Epoch 9/10\n",
      "686/686 [==============================] - 127s 185ms/step - loss: 2.0743\n",
      "Epoch 10/10\n",
      "686/686 [==============================] - 127s 185ms/step - loss: 1.9662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ce5825340>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits = True,\n",
    "    reduction = 'none'\n",
    ")\n",
    "\n",
    "lyricist.compile(loss=loss, optimizer=optimizer)\n",
    "lyricist.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c86e936",
   "metadata": {},
   "source": [
    "val_loss의 값이 1.9662로 감소한 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd04d1",
   "metadata": {},
   "source": [
    "## 가사 생성하기\n",
    "\n",
    "generate_text 함수를 이용하여 모델에게 시작 문장을 전달하고, 그 문장을 바탕으로 모델이 작사를 하도록 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddeccaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(lyricist, tokenizer, init_sentence=\"<start>\", max_len=15):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 생성\n",
    "    #    1. 입력받은 문장의 텐서를 입력\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 검출\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 이어 붙임\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성 종료\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = lyricist(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f0ed826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> you are the one <end> '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> You are\", max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc68ecb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you <end> '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> I love\", max_len=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df44d4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i was in the dominican big papi ortiz <end> '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> I was in\", max_len=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7e6c2",
   "metadata": {},
   "source": [
    "## 회고\n",
    "* 순환신경망 모델의 구조를 좀 더 면밀히 학습해야 할 필요성을 느꼈다. 다행히도 제시한 과제에 맞게 결과물이 도출되었지만 순환신경망 모델의 구조에 대한 이해가 아직 제대로 정립이 되지 않아 복잡하게 느껴져 과제 진행에 있어 설명하는 것에 한계를 체감하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec3a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
